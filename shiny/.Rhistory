)
sum(syuzhet_vector)
mean(syuzhet_vector)
summary(syuzhet_vector)
percent_vals <- get_percentage_values(syuzhet_vector, bins = 10)
plot(
percent_vals,
type="l",
main="Twitter Sentiment Analysis Using Percentage-Based Means",
xlab = "Chunks",
ylab= "Emotional Valence",
col="red"
)
barplot(
sort(colSums(prop.table(sentiment[, 1:8]))),
horiz = TRUE,
cex.names = 0.7,
las = 1,
main = "Emotions in text", xlab="Percentage"
)
valence <- (sentiment[, 9]*-1) + sentiment[, 10]
#valence
#pander::pandoc.table(sentiment[, 9:10])
#total sentiment sore of all texts
#png("SentimentScore", width=12, height=8, units="in", res=300)
ggplot(data = Totalsentiment, aes(x = sentiment, y = count)) +
geom_bar(aes(fill = sentiment), stat = "identity") +
theme(legend.position = "none") +
xlab("Sentiment") +ylab("Total Count") + ggtitle("Total Sentiment Score")
View(data2)
View(data2)
View(data)
View(data)
barplot(
sort(colSums(prop.table(sentiment[, 1:8]))),
horiz = TRUE,
cex.names = 0.7,
las = 1,
main = "Emotions in text", xlab="Percentage"
)
texts <- as.vector(data2$text_clean)
head(texts)
retweetcounts <- as.vector(data2$retweetCount)
head(retweetcounts)
#fetch sentiment words from texts
sentiment <- get_nrc_sentiment(texts)
#change the data.csv encode to UTF-8
data2<- data
# Remove duplicates
data <- unique(data)
# Place NAs in empty cells in location column
data$location <- replace(data$location, data$location=="",NA)
# Remove location rows with NAs
data <- data[complete.cases(data$location), ]
# Clean up emojis
data$text_clean <- str_replace_all(data$text,"[^[:graph:]]", " ")
# Remove punctuation
data$text_clean <- gsub("[[:punct:]]", "", data$text_clean)
# Remove control characters
data$text_clean <- gsub("[[:cntrl:]]", "", data$text_clean)
# Remove digits
data$text_clean <- gsub('\\d+', '', data$text_clean)
# Remove URLs from string
data$text_clean <- gsub("(f|ht)tp(s?)://(.*)[.][a-z]+", "", data$text_clean)
#change the data.csv encode to UTF-8
data2<- data
texts <- as.vector(data2$text_clean)
head(texts)
retweetcounts <- as.vector(data2$retweetCount)
head(retweetcounts)
#fetch sentiment words from texts
sentiment <- get_nrc_sentiment(texts)
data2 <- cbind(texts,retweetcounts,sentiment)
View(data2)
View(data2)
#count the sentiment words by category
Totalsentiment <- data.frame(colSums(data2[,c(2:11)]))
names(Totalsentiment) <- "count"
Totalsentiment <- cbind("sentiment"= rownames(Totalsentiment), Totalsentiment)
rownames(Totalsentiment) <- NULL
#total sentiment sore of all texts
#png("SentimentScore", width=12, height=8, units="in", res=300)
ggplot(data = Totalsentiment, aes(x = sentiment, y = count)) +
geom_bar(aes(fill = sentiment), stat = "identity") +
theme(legend.position = "none") +
xlab("Sentiment") +ylab("Total Count") + ggtitle("Total Sentiment Score")
#count the sentiment words by category
Totalsentiment <- data.frame(colSums(data2[,c(3:11)]))
names(Totalsentiment) <- "count"
Totalsentiment <- cbind("sentiment"= rownames(Totalsentiment), Totalsentiment)
rownames(Totalsentiment) <- NULL
#total sentiment sore of all texts
#png("SentimentScore", width=12, height=8, units="in", res=300)
ggplot(data = Totalsentiment, aes(x = sentiment, y = count)) +
geom_bar(aes(fill = sentiment), stat = "identity") +
theme(legend.position = "none") +
xlab("Sentiment") +ylab("Total Count") + ggtitle("Total Sentiment Score")
angry_items <- which(sentiment$anger > 0)
#texts[angry_items]
joy_items <- which(sentiment$joy > 0)
#texts[joy_items]
#install.packages("pander")
#pander::pandoc.table(sentiment[, 1:8], split.table = Inf)
valence <- (sentiment[, 9]*-1) + sentiment[, 10]
#valence
barplot(
sort(colSums(prop.table(sentiment[, 1:8]))),
horiz = TRUE,
cex.names = 0.7,
las = 1,
main = "Emotions in text", xlab="Percentage"
)
syuzhet_vector <- get_sentiment(texts, method="syuzhet")
head(syuzhet_vector)
sum(syuzhet_vector)
mean(syuzhet_vector)
summary(syuzhet_vector)
percent_vals <- get_percentage_values(syuzhet_vector, bins = 10)
plot(
percent_vals,
type="l",
main="Twitter Sentiment Analysis Using Percentage-Based Means",
xlab = "Chunks",
ylab= "Emotional Valence",
col="red"
)
View(data2)
View(data2)
View(Totalsentiment)
View(Totalsentiment)
View(sentiment)
View(sentiment)
View(data2)
View(data2)
data2 <- cbind(texts,retweetcounts,sentiment)
data2 <- cbind("sentiment_score"= rownames(data2), syuzhet_vector)
rownames(data2) <- NULL
View(data2)
View(data2)
data2 <- cbind(texts,retweetcounts,sentiment,syuzhet_vector)
#data2 <- cbind("sentiment_score"= rownames(data2), syuzhet_vector)
#rownames(data2) <- NULL
data2 <- cbind(texts,retweetcounts,syuzhet_vector,sentiment)
#data2 <- cbind("sentiment_score"= rownames(data2), syuzhet_vector)
#rownames(data2) <- NULL
data2$sentiment_class <- ifelse(data2$syuzhet_vector >= 0 , "Positive", "Negative")
View(data2)
View(data2)
aggregate(data2$retweetcounts, by=list(Category=data2$sentiment_class), FUN=sum)
#aggregate(data2$retweetcounts, by=list(Category=data2$sentiment_class), FUN=sum)
ggplot(data2, aes(x=sentiment_class, y=retweetcounts)) + geom_bar(stat="identity")
#aggregate(data2$retweetcounts, by=list(Category=data2$sentiment_class), FUN=sum)
ggplot(data2, aes(x=sentiment_class, y=retweetcounts),fill = sentiment_class) + geom_bar(stat="identity")
#aggregate(data2$retweetcounts, by=list(Category=data2$sentiment_class), FUN=sum)
ggplot(data2, aes(x=sentiment_class, y=retweetcounts,fill = sentiment_class)) + geom_bar(stat="identity")
install.packages("qdapRegex")
library(qdapRegex)
x <- paste0("I went to Washington Heights, NY for food! ",
"It's in West ven,PA, near Bolly Bolly Bolly, CA!",
"I like Movies, PG13")
rm_city_state(x)
install.packages("qdapRegex")
library('qdapRegex')
x <- paste0("I went to Washington Heights, NY for food! ",
"It's in West ven,PA, near Bolly Bolly Bolly, CA!",
"I like Movies, PG13")
rm_city_state(x)
ex_city_state(x)
x <- paste0("I went to Washington Heights, NY 54321 for food! ",
"It's in West ven,PA 12345, near Bolly Bolly Bolly, CA12345-1234!",
"hello world")
rm_city_state_zip(x)
ex_city_state_zip(x)
View(data)
View(data)
city,state <- ex_city_state(data2$texts)
city_state <- ex_city_state(data2$texts)
remove(city_state)
data2$city_state <- ex_city_state(data2$texts)
remove(city_state)
data2$city_state <- ex_city_state(data$location)
data2$city_state <- ex_city_state(data$location)
str_split_fixed(data2$city_state, "ï¼Œ", 2)
str_split_fixed(data2$city_state, ", ", 2)
data2$city,data2$state <- str_split_fixed(data2$city_state, ", ", 2)
data2[,c("City","State"):=data.table(str_split_fixed(data2$city_state, ", ", 2))]
library(operator)
install.packages("data.table")
#install.packages('wordcloud')
library(wordcloud)
#install.packages('stringr')
library(stringr)
#install.packages("RColorBrewer")
library(RColorBrewer)
library(tm)
library(twitteR)
library(plyr)
#install.packages('syuzhet')
library(ggplot2)
library(syuzhet)
data <- read.csv("data.csv")
# Remove duplicates
data <- unique(data)
# Place NAs in empty cells in location column
data$location <- replace(data$location, data$location=="",NA)
# Remove location rows with NAs
data <- data[complete.cases(data$location), ]
# Clean up emojis
data$text_clean <- str_replace_all(data$text,"[^[:graph:]]", " ")
# Remove punctuation
data$text_clean <- gsub("[[:punct:]]", "", data$text_clean)
# Remove control characters
data$text_clean <- gsub("[[:cntrl:]]", "", data$text_clean)
# Remove digits
data$text_clean <- gsub('\\d+', '', data$text_clean)
# Remove URLs from string
data$text_clean <- gsub("(f|ht)tp(s?)://(.*)[.][a-z]+", "", data$text_clean)
#change the data.csv encode to UTF-8
#data2<-read.csv("data.csv")
data2 <- data
# Remove duplicates
data <- unique(data)
# Place NAs in empty cells in location column
data$location <- replace(data$location, data$location=="",NA)
# Remove location rows with NAs
data <- data[complete.cases(data$location), ]
# Clean up emojis
data$text_clean <- str_replace_all(data$text,"[^[:graph:]]", " ")
# Remove punctuation
data$text_clean <- gsub("[[:punct:]]", "", data$text_clean)
# Remove control characters
data$text_clean <- gsub("[[:cntrl:]]", "", data$text_clean)
# Remove digits
data$text_clean <- gsub('\\d+', '', data$text_clean)
# Remove URLs from string
data$text_clean <- gsub("(f|ht)tp(s?)://(.*)[.][a-z]+", "", data$text_clean)
#change the data.csv encode to UTF-8
#data2<-read.csv("data.csv")
data2 <- data
texts <- as.vector(data2$text_clean)
head(texts)
retweetcounts <- as.vector(data2$retweetCount)
head(retweetcounts)
#fetch sentiment words from texts
sentiment <- get_nrc_sentiment(texts)
data2 <- cbind(texts,retweetcounts,sentiment)
#count the sentiment words by category
Totalsentiment <- data.frame(colSums(data2[,c(3:11)]))
names(Totalsentiment) <- "count"
Totalsentiment <- cbind("sentiment"= rownames(Totalsentiment), Totalsentiment)
rownames(Totalsentiment) <- NULL
#total sentiment sore of all texts
#png("SentimentScore", width=12, height=8, units="in", res=300)
ggplot(data = Totalsentiment, aes(x = sentiment, y = count)) +
geom_bar(aes(fill = sentiment), stat = "identity") +
theme(legend.position = "none") +
xlab("Sentiment") +ylab("Total Count") + ggtitle("Total Sentiment Score")
angry_items <- which(sentiment$anger > 0)
#texts[angry_items]
joy_items <- which(sentiment$joy > 0)
#texts[joy_items]
valence <- (sentiment[, 9]*-1) + sentiment[, 10]
#valence
barplot(
sort(colSums(prop.table(sentiment[, 1:8]))),
horiz = TRUE,
cex.names = 0.7,
las = 1,
main = "Emotions in text", xlab="Percentage"
)
syuzhet_vector <- get_sentiment(texts, method="syuzhet")
head(syuzhet_vector)
sum(syuzhet_vector)
mean(syuzhet_vector)
summary(syuzhet_vector)
percent_vals <- get_percentage_values(syuzhet_vector, bins = 10)
plot(
percent_vals,
type="l",
main="Twitter Sentiment Analysis Using Percentage-Based Means",
xlab = "Chunks",
ylab= "Emotional Valence",
col="red"
)
# add syuzhet_vector into data2
data2 <- cbind(texts,retweetcounts,syuzhet_vector,sentiment)
View(data2)
View(data2)
# add syuzhet_vector into data2
data2 <- cbind(texts,retweetcounts,syuzhet_vector,sentiment)
data2$sentiment_class <- ifelse(data2$syuzhet_vector >= 0 , "Positive", "Negative")
#aggregate(data2$retweetcounts, by=list(Category=data2$sentiment_class), FUN=sum)
ggplot(data2, aes(x=sentiment_class, y=retweetcounts,fill = sentiment_class)) + geom_bar(stat="identity")
install.packages("qdapRegex")
library('qdapRegex')
x <- paste0("I went to Washington Heights, NY for food! ",
"It's in West ven,PA, near Bolly Bolly Bolly, CA!",
"I like Movies, PG13")
rm_city_state(x)
ex_city_state(x)
data2$city_state <- ex_city_state(data$location)
#install.packages("data.table")
library(data.table)
data2[,c("City","State"):= data.table(str_split_fixed(data2$city_state, ", ", 2))]
#install.packages("data.table")
library(data.table)
data2[,c("City","State")::= data.table(str_split_fixed(data2$city_state, ", ", 2))]
#install.packages("data.table")
library(data.table)
data.table(str_split_fixed(data2$city_state, ", ", 2))
View(data)
View(data)
#install.packages("data.table")
library(data.table)
data2[,c("City","State") = data.table(str_split_fixed(data2$city_state, ", ", 2))
#install.packages("data.table")
#library(data.table)
data2[,c("City","State") <- data.table(str_split_fixed(data2$city_state, ", ", 2))
#install.packages("data.table")
#library(data.table)
c("City","State") <- str_split_fixed(data2$city_state, ", ", 2)
#install.packages("data.table")
#library(data.table)
("City","State") <- str_split_fixed(data2$city_state, ", ", 2)
#install.packages("data.table")
#library(data.table)
("City","State") <- str_split_fixed(data2$city_state, ", ", 2)
#install.packages("data.table")
#library(data.table)
("City","State") <- str_split_fixed(data2$city_state, ", ", 2)
#install.packages("data.table")
#library(data.table)
("City","State") <- str_split_fixed(data2$city_state, ", ", 2)
#install.packages("data.table")
#library(data.table)
#("City","State") <- str_split_fixed(data2$city_state, ", ", 2)
str_split_fixed(data2$city_state, ", ", 2)
#install.packages("data.table")
#library(data.table)
#("City","State") <- str_split_fixed(data2$city_state, ", ", 2)
str_split_fixed(data2$city_state, ", ", 2)[1]
#install.packages("data.table")
#library(data.table)
#("City","State") <- str_split_fixed(data2$city_state, ", ", 2)
str_split_fixed(data2$city_state, ", ", 2)[:,1]
#install.packages("data.table")
#library(data.table)
#("City","State") <- str_split_fixed(data2$city_state, ", ", 2)
str_split_fixed(data2$city_state, ", ", 2)
#install.packages("data.table")
#library(data.table)
#("City","State") <- str_split_fixed(data2$city_state, ", ", 2)
data2 %>% str_split_fixed(data2$city_state, ", ", 2)
#install.packages("data.table")
#library(data.table)
#("City","State") <- str_split_fixed(data2$city_state, ", ", 2)
out <- str_split_fixed(data2$city_state, ", ", 2)
do.call(rbind, out)
View(out)
View(out)
#install.packages("data.table")
#library(data.table)
#("City","State") <- str_split_fixed(data2$city_state, ", ", 2)
out <- str_split_fixed(data2$city_state, ", ", 2)
head(out$V1)
#install.packages("data.table")
#library(data.table)
#("City","State") <- str_split_fixed(data2$city_state, ", ", 2)
out <- str_split_fixed(data2$city_state, ", ", 2)
out[,c(1)]
#install.packages("data.table")
#library(data.table)
#("City","State") <- str_split_fixed(data2$city_state, ", ", 2)
out <- str_split_fixed(data2$city_state, ", ", 2)
data2$city <- out[,c(1)]
#install.packages("data.table")
#library(data.table)
#("City","State") <- str_split_fixed(data2$city_state, ", ", 2)
out <- str_split_fixed(data2$city_state, ", ", 2)
data2$city <- out[,c(1)]
data2$state <- out[,c(2)]
data$city_state <- ex_city_state(data$location)
out <- str_split_fixed(data$city_state, ", ", 2)
data$city <- out[,c(1)]
data$state <- out[,c(2)]
write.csv(file="data_with_city.csv", x=data)
#write.csv(file="data_with_city.csv", x=data)
sum(data$city_state != "")
#write.csv(file="data_with_city.csv", x=data)
sum(data$city_state is not NA)
#write.csv(file="data_with_city.csv", x=data)
sum(data$city_state != NA)
#write.csv(file="data_with_city.csv", x=data)
sum(is.na(data$city))
#write.csv(file="data_with_city.csv", x=data)
sum(is.na(data$city_state))
View(data2)
View(data2)
View(data2)
View(data2)
#check how many records still with no city_state
write.csv(file="data_with_city_sentiment.csv", x=data2)
#sum(is.na(data$city_state))
#aggregate(data2$retweetcounts, by=list(Category=data2$sentiment_class), FUN=sum)
ggplot(data2, aes(x=sentiment_class, y=retweetcounts,fill = sentiment_class)) + geom_bar(stat="identity")
library(xlsx) #load the package
write.xlsx(x = data2, file = "data_sentiment.xlsx",
sheetName = "TestSheet", row.names = FALSE)
write.csv(file="test_data_with_city_sentiment.xlsx", x=data2)
write.csv(file="test_data_with_city_sentiment.xlsx", x=data2)
write.csv(file="test_data_with_city_sentiment.xlsx", x=data2)
#total sentiment sore of all texts
#png("SentimentScore", width=12, height=8, units="in", res=300)
ggplot(data = Totalsentiment, aes(x = sentiment, y = count)) +
geom_bar(aes(fill = sentiment), stat = "identity") +
theme(legend.position = "none") +
xlab("Sentiment") +ylab("Total Count") + ggtitle("Total Sentiment Score")
barplot(
sort(colSums(prop.table(sentiment[, 1:8]))),
horiz = TRUE,
cex.names = 0.7,
las = 1,
main = "Emotions in text", xlab="Percentage"
)
data3 <- read.csv("state_clean.csv")
#change the data.csv encode to UTF-8
data2 <- data3
texts <- as.vector(data2$text_clean)
head(texts)
retweetcounts <- as.vector(data2$retweetCount)
head(retweetcounts)
#fetch sentiment words from texts
sentiment <- get_nrc_sentiment(texts)
data2 <- cbind(texts,retweetcounts,sentiment)
#change the data.csv encode to UTF-8
data2 <- data
texts <- as.vector(data2$text_clean)
head(texts)
retweetcounts <- as.vector(data2$retweetCount)
head(retweetcounts)
data3 <- read.csv("state_clean.csv")
View(data3)
View(data3)
#change the data.csv encode to UTF-8
data2 <- data3
texts <- as.vector(data2$text_clean)
head(texts)
retweetcounts <- as.vector(data2$retweetCount)
head(retweetcounts)
syuzhet_vector <- get_sentiment(texts, method="syuzhet")
head(syuzhet_vector)
sum(syuzhet_vector)
mean(syuzhet_vector)
summary(syuzhet_vector)
# add syuzhet_vector into data2
#data2 <- cbind(texts,retweetcounts,syuzhet_vector,sentiment)
data2$syuzhet_vector <- syuzhet_vector
data2$sentiment_class <- ifelse(data2$syuzhet_vector >= 0 , "Positive", "Negative")
data2$sentiment_class <- ifelse(data2$syuzhet_vector >= 0 , "Positive", "Negative")
#aggregate(data2$retweetcounts, by=list(Category=data2$sentiment_class), FUN=sum)
ggplot(data2, aes(x=sentiment_class, y=retweetcounts,fill = sentiment_class)) + geom_bar(stat="identity")
write.csv(file="new_data_with_city_sentiment.csv", x=data2)
write.csv(file="new_data_with_city_sentiment.csv", x=data2)
library(magick)
motion <- image_read("/Users/panpancheng/Documents/study/5701 EDA/project/pictures/gif/Dynamic Map.gif")
motion <- image_scale(motion, "300")
#print(motion)
print(motion)
plot(motion)
plot(motion)
class(motion)
image_animate(image_scale(motion, "200x200"), fps = 1, dispose = "previous")
image_animate(motion)
image_animate(motion)
print(motion)
raster::plotRGB(motion)
library(ggplot2)
data <- read.csv("clean_felonies_offense.csv")
View(data)
View(data)
shiny::runApp('Documents/study/capstone/shiny/Crime_Prediction')
runApp('Documents/study/capstone/shiny/Crime_Prediction')
runApp('Documents/study/capstone/shiny/Crime_Prediction')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
install.packages('shinydashboard')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
install.packages('highcharter')
install.packages('wordcloud2')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
install.packages('DT')
install.packages('leaflet')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/shiny/crime_v1')
runApp('Documents/study/capstone/Git /precrime/shiny')

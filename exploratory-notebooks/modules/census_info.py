"""Functions for working with American FactFinder files."""
import numpy as np
import pandas as pd

# For use in figuring out which census tracts are actually located in
# New York City. These correspond to the five counties that make up the city.
__PREFIXES = {
    'Bronx': '36005',
    'Brooklyn': '36047',
    'Staten Island': '36085',
    'Queens': '36081',
    'Manhattan': '36061'
}


def get_boro_prefixes():
    """Return the prefix dictionary."""
    return __PREFIXES


def get_full_census_tract_id(boro, tract_2010):
    """Convert (boro, tract) in NY Shapefile to census tract ID.

    Parameters
    ----------
    boro : string
        One of 'Brooklyn', 'Staten Island', etc.
    tract_2010 : string
        A six-character string representing the census tract ID.

    Returns
    -------
    FullCensusTractID : string
        The fully qualified ID for referring to a census tract
        in a file generated by American FactFinder
    """
    return '1400000US' + str(__PREFIXES[boro]) + str(tract_2010)


def read_census_info(path='../census_info/'):
    """Load the data from American FactFinder into a single dataframe.

    Parameters
    ----------
    path : string, optional
        The directory where the American FactFinder CSV files
        are located

    Returns
    -------
    merged : DataFrame
        A Pandas DataFrame with index 'GEO.id' (a fully qualified census
        tract ID) and the following columns:
        'GEO.id2': a numeric version of the census tract
        'GEO.display-label': A string description of the census tract
        'Population': The census tract population
        'Median_Household_Income': The median household income
        'Percent_Bachelors_Degree': The percent of the population with
            a bachelors degree or above
    """
    # Load the three files individually:
    inc = pd.read_csv(
        path + 'income/ACS_15_5YR_S1903_with_ann.csv',
        index_col='GEO.id', skiprows=[1]
    )
    # To load the column definitions:
    # inc_cols = pd.read_csv(
    #     path + 'income/ACS_15_5YR_S1903_metadata.csv',
    #     header=None, index_col=0, squeeze=True
    # )

    age_sex = pd.read_csv(
        path + 'age_sex/ACS_15_5YR_S0101_with_ann.csv',
        index_col='GEO.id', skiprows=[1]
    )
    # To load the column definitions:
    # age_sex_cols = pd.read_csv(
    #     path + 'age_SEX/ACS_15_5YR_S0101_metadata.csv',
    #     header=None, index_col=0, squeeze=True
    # )

    edu = pd.read_csv(
        path + 'edu/ACS_15_5YR_S1501_with_ann.csv',
        index_col='GEO.id', skiprows=[1]
    )
    # To load the column definitions:
    # edu_cols = pd.read_csv(
    #     path + 'edu/ACS_15_5YR_S1501_metadata.csv',
    #     header=None, index_col=0, squeeze=True
    # )

    # Get only the rows that correspond to census tracts located in NYC
    nyc_pop = age_sex[age_sex.index.map(lambda x: x[9:14]).isin(
        get_boro_prefixes().values()
    )]

    # Merge the other two files
    merged = pd.merge(
        pd.merge(
            # HC01_EST_VC01 = Total Population
            nyc_pop[['GEO.id2', 'GEO.display-label', 'HC01_EST_VC01']],
            inc[['HC02_EST_VC02']],     # Median Household Income
            left_index=True,
            right_index=True
        ),
        edu[['HC02_EST_VC18']],         # Percent of population with bachelors+
        left_index=True,
        right_index=True
    )

    # Rename the data columns with friendlier names
    data_columns = [
        'Population',
        'Median_Household_Income',
        'Percent_Bachelors_Degree'
    ]
    merged.columns = np.concatenate((merged.columns[:2], data_columns))

    # Convert the data columns to have numeric type, with NaN for rows
    # missing data.
    for col in data_columns:
        merged[col] = pd.to_numeric(merged[col], errors='coerce')

    return merged
